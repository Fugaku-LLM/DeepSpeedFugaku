# Tokenize Training Dataset with original tokenizer

GPT-Fugaku ã§ã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® GPT2BPETokenizer(BytePairEncoding)ã§ã¯ãªãã€SentencePiece ã‚’ç”¨ã„ãŸ Tokenizer ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚ã¾ãŸã€Tokenizer ã® version ã‚‚è¤‡æ•°ã‚ã‚Šã€ãã‚Œãã‚Œã® Tokenizer ã§ binarize ã—ãŸ`.bin`, `.idx`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

## Tokenize ã™ã‚‹ãŸã‚ã®ç’°å¢ƒ

DeepSpeedFugaku ã®ã‚³ãƒ¼ãƒ‰ã¯ã€Training ã‚’è¡Œã†ãŸã‚ã® CPU ç§»æ¤ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã™ãŒã€Tokenize ã™ã‚‹ãŸã‚ã®å‡¦ç†ã§å¿…è¦ãªãƒ—ãƒ­ã‚»ã‚¹ã® CPU ç§»æ¤ã¯è¡Œãˆã¦ã„ã¾ã›ã‚“ã€‚ã¾ãŸã€Text Generation ã«ã¤ã„ã¦ã‚‚åŒæ§˜ã§ã™ã€‚

ãã®ãŸã‚ã€Tokenize ã‚’è¡Œã†ãŸã‚ã«ã¯ã€GPU ç’°å¢ƒã«ã¦ç’°å¢ƒã‚’æ§‹ç¯‰ã—ã€Tokenize ã‚’è¡Œã†å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### ç’°å¢ƒæ§‹ç¯‰

ç’°å¢ƒæ§‹ç¯‰ã¯é€šå¸¸ã® Megatron-DeepSpeed ã®ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•ã¨åŒã˜ã§ã™ãŒã€`nltk`, `sentencepiece`ãªã©ã®å­¦ç¿’ã«ãŠã„ã¦ã¯ä½¿ç”¨ã—ãªã„ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

(`scripts/tokenize-gpu-requirements.txt`ã« CUDA11.7 ç’°å¢ƒã§ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ç”¨ã® requirements.txt ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚)
Megatron-DeepSpeed ã®ç’°å¢ƒæ§‹ç¯‰æ–¹æ³•ã®è©³ç´°ã«ã¤ã„ã¦ã¯ã€[ã“ã¡ã‚‰ã®è¨˜äº‹ã‚’ã”è¦§ãã ã•ã„](https://zenn.dev/turing_motors/articles/04c1328bf6095a)

### dataset ã®ç”¨æ„

Fugaku ã§ dataset ã‚’ download ã—ã¦ã‚‚è‰¯ã„ã§ã™ãŒã€å‡¦ç†ã®ç”¨æ„ã•ãªã©ã‹ã‚‰ã€é€šå¸¸ã® CPU ç’°å¢ƒã§ã®ä½œæ¥­ã‚’æ¨å¥¨ã—ã¾ã™.
(å®Ÿã¯ã€Fugaku ã® login ãƒãƒ¼ãƒ‰ã¯ Fujitsu è£½ã® chip ã§ã¯ãªã„ã®ã§ã€é€šå¸¸ã® pip install ã§ä½œæ¥­ãŒã§ãã¾ã™ãŒã€login ãƒãƒ¼ãƒ‰ã«è² è·ã‚’ã‹ã‘ã‚‹è¡Œç‚ºã«ãªã‚‹ã®ã§æ¨å¥¨ã§ãã¾ã›ã‚“)

(Fugaku ä¸Šã«ã€ä»¥ä¸‹ã®å‡¦ç†ã‚’ã—ãŸ tokenize å‰ã®ãƒ‡ãƒ¼ã‚¿ã¨ã€ä¸€éƒ¨ã® Tokenize æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’`/data/hp190122/share/dataset`ã«ç½®ã„ã¦ã‚ã‚Šã¾ã™ã€‚é©æ™‚ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚)

```bash

cd DeepSpeedFugaku

python -m venv .env

source .env/bin/activate

pip install wikiextractor
```

æœ€æ–°ã® Wikipeida dump ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
(https://github.com/rioyokotalab/DeepSpeedFugaku/blob/training/feature/v2-tokenizer/dataset/wikipedia/wikidump_download.py#L41 ã®`["ja]"`ã‚’`["ja", "en"]`ã¨ã™ã‚‹ã¨æ—¥æœ¬èªã¨è‹±èªã® wikipedia ãŒ download ã§ãã¾ã™ã€‚)

```bash
python dataset/wikipedia/wikidump_download.py
```

å®Ÿè¡Œã™ã‚‹ã¨`data/wikipedia/processed`ã«`ja`ã‚„`en`ã¨ã„ã†ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒç”Ÿæˆã•ã‚Œã¾ã™ã€‚(`["ja"]`ã¨ã—ãŸå ´åˆã¯ã€`ja`ã ã‘ã—ã‹ç”Ÿæˆã•ã‚Œã¾ã›ã‚“)

jsonl å½¢å¼ã® file ã«ã—ã¾ã™ã€‚

`dataset/wikipedia/merge_files.sh`ã«ã‚ã‚‹ script ã‚’åˆ©ç”¨ã—ã¦ã€1 ã¤ã«ã¾ã¨ã‚ã‚‹ä½œæ¥­ã‚’è¡Œã„ã¾ã™ã€‚

Japanese Wikipedia:

```bash
bash dataset/wikipedia/merge_files.sh \
  data/wikipedia/processed/ja/AA \
  data/wikipedia/merged/ja \
  ja_merged
```

English Wikipedia:

```bash
bash dataset/wikipedia/merge_files.sh \
  data/wikipedia/processed/en/AA \
  data/wikipedia/merged/en \
  en_merged_1

bash dataset/wikipedia/merge_files.sh \
  data/wikipedia/processed/en/AB \
  data/wikipedia/merged/en \
  en_merged_2

bash dataset/wikipedia/merge_files.sh \
  data/wikipedia/merged/en \
  data/wikipedia/merged/en \
  en_merged
```

ã“ã‚Œã§ã€Japanese Wiki, English Wiki ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„ã§ãã¾ã—ãŸã€‚ğŸ‰

### Tokenize ã®å®Ÿè¡Œ

`DeepSpeedFugaku/.env`ã«ä»®æƒ³ç’°å¢ƒã‚’ä½œæˆã—ã¦ã„ã‚‹å‰æã§ã™ãŒã€`scripts/`ã« Tokenizer-V1, Tokenizer-V2 ãã‚Œãã‚Œã® Tokenizer ã§ data ã‚’ binarize ã™ã‚‹ãŸã‚ã® script ã‚’ç”¨æ„ã—ã¦ã„ã¾ã™ã€‚(æ¨ªç”°ç ” lab server ã«ã¦å‹•ä½œã™ã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ãŒã€é©æ™‚ãã‚Œãã‚Œã®ç’°å¢ƒã«ã‚ã‚ã›ã¦å¤‰ãˆã¦ãã ã•ã„ã€‚)

æ³¨æ„: `dataset/wikipedia/merged/ja/ja_merged.json`ã« Wikipedia ã®ãƒ‡ãƒ¼ã‚¿ãŒç”¨æ„ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã«ã—ã¦ã„ã¾ã™ã€‚
(äº‹å‰ã«ã€`scripts/`ã«ã‚ã‚‹ shell script ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚)

```bash
# Tokenizer-V1
cd DeepSpeedFugaku

ybatch scripts/tokenize-v1.sh

```

https://github.com/rioyokotalab/DeepSpeedFugaku/blob/training/feature/v2-tokenizer/scripts/tokenize-v1.sh#L13-L14 ã®éƒ¨åˆ†ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€æ—¥æœ¬èªã¨è‹±èªã® vocab size ã‚’å¤‰æ›´ã—ãŸ Tokenizer ã§ã® Tokenize ã‚’è¡Œã†ã“ã¨ãŒã§ãã¾ã™ã€‚

```bash
# Tokenizer-V2

cd DeepSpeedFugaku

ybatch scripts/tokenize-v2.sh

```

binarized ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯`DeepSpeedFugaku/datasets/wikipedia/binarized`ã«å‡ºåŠ›ã•ã‚Œã¾ã™ã€‚`.bin`ã¨`.idx`ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸¡æ–¹ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚

#### Hinaori(æ¨ªç”°ç ” lab server)ã‹ã‚‰ Fugaku ã¸ã®ãƒ‡ãƒ¼ã‚¿ Transfer

sftp ã‚’ç”¨ã„ã‚‹ã®ãŒè‰¯ã„ã§ã—ã‚‡ã†ã€‚
æ¨ªç”°ç ”ã® lab server ä¸Šã‹ã‚‰ fugaku ã¸ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã« ssh config ã¨ ç§˜å¯†éµã‚’ç”¨æ„ã—ã¾ã™ã€‚

ãã®å¾Œ

```bash
sftp fugaku

sftp > put -r <from> <to>
```

ã®ã‚ˆã†ãªå½¢ã§ç§»å‹•ã™ã‚Œã°è‰¯ã„ã§ã—ã‚‡ã†ã€‚

ä¾‹:

```bash
sftp fugaku
sftp> put -r datasets/wikipedia/binarized/v2-code20k_en40k_ja80k data/wikipedia/binarized
```
